{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **CS224W - Colab 5**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/scpd-proed/XCS224W-Colab5/blob/main/Notebook/XCS224W_Colab5.ipynb)\n",
    "\n",
    "Before opening the colab with the badge, you would need to allow Google Colab to access the GitHub private repositories. Please check therefore [this tutorial](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb#:~:text=Navigate%20to%20http%3A%2F%2Fcolab,to%20read%20the%20private%20files.).\n",
    "\n",
    "If colab is opened with this badge, make sure please **save copy to drive** in 'File' menu before running the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "In this final Colab we will continue experimenting with advanced topics in GNNs. Specifically, we will look at different techniques for scaling up GNNs using PyTorch Geometric, DeepSNAP and NetworkX. In the previous Colab we worked with PyTorch Geometric's `NeighborSampler` to scale up training and testing on the OGB `arxiv` dataset and now we will be using DeepSNAP and NetworkX, to implement our own simplified version of `NeighborSampler` and run experiments with different sampling ratios on the Cora graph.\n",
    "\n",
    "Lastly, we will partition the Cora graph into clusters by using different partition algorithms and then train the models using a vanilla Cluster-GCN.\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSaetj53YnT6"
   },
   "source": [
    "# Device\n",
    "You likely will want to us a GPU for this Colab.\n",
    "\n",
    "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCK7krJdp4o8"
   },
   "source": [
    "# Setup\n",
    "As discussed in the first Colabs, the installation of PyG on Colab can be a little bit tricky. First let us check which version of PyTorch you are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vkP8pA1qBE5",
    "outputId": "2dc5f100-684c-4efd-f153-a5a54649f583"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67gOQITlCNQi"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_m9l6OYCQZP",
    "outputId": "3a1915f3-4d3a-462a-cf7c-91d25cb4920d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "COMMAND_MODE=unix2003\n",
      "CONDA_DEFAULT_ENV=xcs224w\n",
      "CONDA_EXE=/Users/Kauntey.Shah/anaconda3/bin/conda\n",
      "CONDA_PREFIX=/Users/Kauntey.Shah/anaconda3/envs/xcs224w\n",
      "CONDA_PREFIX_1=/Users/Kauntey.Shah/anaconda3\n",
      "CONDA_PROMPT_MODIFIER='(xcs224w) '\n",
      "CONDA_PYTHON_EXE=/Users/Kauntey.Shah/anaconda3/bin/python\n",
      "CONDA_SHLVL=2\n",
      "FORCE_COLOR=1\n",
      "GIT_PAGER=cat\n",
      "HOME=/Users/Kauntey.Shah\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "JAVA_HOME=/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home\n",
      "JPY_PARENT_PID=91925\n",
      "JPY_SESSION_NAME=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook/XCS224W_Colab5.ipynb\n",
      "LC_CTYPE=en_GB.UTF-8\n",
      "LOGIN_SHELL=1\n",
      "LOGNAME=Kauntey.Shah\n",
      "MANPATH=/opt/homebrew/share/man::\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "OLDPWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PAGER=cat\n",
      "PATH='/Users/Kauntey.Shah/anaconda3/envs/xcs224w/bin:/Users/Kauntey.Shah/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion Tech Preview.app/Contents/Public:/usr/local/share/dotnet:/usr/local/munki:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home:/Users/Kauntey.Shah/Projects/development/tools/apache-maven-3.8.6/bin:/Users/Kauntey.Shah/Library/Application Support/Coursier/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home'\n",
      "PWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=2\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.Dud8dYkHAA/Listeners\n",
      "TERM=xterm-color\n",
      "TERMINAL_EMULATOR=JetBrains-JediTerm\n",
      "TERM_SESSION_ID=c3231f94-ef18-4397-b5a9-e30d8803575e\n",
      "TMPDIR=/var/folders/f1/qzsy2rls2q719_dqggb3l7fw0000gq/T/\n",
      "USER=Kauntey.Shah\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "_CE_CONDA=''\n",
      "_CE_M=''\n",
      "__CFBundleIdentifier=com.jetbrains.intellij.ce\n",
      "__CF_USER_TEXT_ENCODING=0x1F7:0:2\n",
      "__INTELLIJ_COMMAND_HISTFILE__=/Users/Kauntey.Shah/Library/Caches/JetBrains/IdeaIC2022.2/terminal/history/XCS224W-history2\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
      "Requirement already satisfied: torch-scatter in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (2.1.1)\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "COMMAND_MODE=unix2003\n",
      "CONDA_DEFAULT_ENV=xcs224w\n",
      "CONDA_EXE=/Users/Kauntey.Shah/anaconda3/bin/conda\n",
      "CONDA_PREFIX=/Users/Kauntey.Shah/anaconda3/envs/xcs224w\n",
      "CONDA_PREFIX_1=/Users/Kauntey.Shah/anaconda3\n",
      "CONDA_PROMPT_MODIFIER='(xcs224w) '\n",
      "CONDA_PYTHON_EXE=/Users/Kauntey.Shah/anaconda3/bin/python\n",
      "CONDA_SHLVL=2\n",
      "FORCE_COLOR=1\n",
      "GIT_PAGER=cat\n",
      "HOME=/Users/Kauntey.Shah\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "JAVA_HOME=/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home\n",
      "JPY_PARENT_PID=91925\n",
      "JPY_SESSION_NAME=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook/XCS224W_Colab5.ipynb\n",
      "LC_CTYPE=en_GB.UTF-8\n",
      "LOGIN_SHELL=1\n",
      "LOGNAME=Kauntey.Shah\n",
      "MANPATH=/opt/homebrew/share/man::\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "OLDPWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PAGER=cat\n",
      "PATH='/Users/Kauntey.Shah/anaconda3/envs/xcs224w/bin:/Users/Kauntey.Shah/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion Tech Preview.app/Contents/Public:/usr/local/share/dotnet:/usr/local/munki:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home:/Users/Kauntey.Shah/Projects/development/tools/apache-maven-3.8.6/bin:/Users/Kauntey.Shah/Library/Application Support/Coursier/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home'\n",
      "PWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=2\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.Dud8dYkHAA/Listeners\n",
      "TERM=xterm-color\n",
      "TERMINAL_EMULATOR=JetBrains-JediTerm\n",
      "TERM_SESSION_ID=c3231f94-ef18-4397-b5a9-e30d8803575e\n",
      "TMPDIR=/var/folders/f1/qzsy2rls2q719_dqggb3l7fw0000gq/T/\n",
      "USER=Kauntey.Shah\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "_CE_CONDA=''\n",
      "_CE_M=''\n",
      "__CFBundleIdentifier=com.jetbrains.intellij.ce\n",
      "__CF_USER_TEXT_ENCODING=0x1F7:0:2\n",
      "__INTELLIJ_COMMAND_HISTFILE__=/Users/Kauntey.Shah/Library/Caches/JetBrains/IdeaIC2022.2/terminal/history/XCS224W-history2\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
      "Requirement already satisfied: torch-sparse in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (0.6.17)\n",
      "Requirement already satisfied: scipy in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from scipy->torch-sparse) (1.24.3)\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "COMMAND_MODE=unix2003\n",
      "CONDA_DEFAULT_ENV=xcs224w\n",
      "CONDA_EXE=/Users/Kauntey.Shah/anaconda3/bin/conda\n",
      "CONDA_PREFIX=/Users/Kauntey.Shah/anaconda3/envs/xcs224w\n",
      "CONDA_PREFIX_1=/Users/Kauntey.Shah/anaconda3\n",
      "CONDA_PROMPT_MODIFIER='(xcs224w) '\n",
      "CONDA_PYTHON_EXE=/Users/Kauntey.Shah/anaconda3/bin/python\n",
      "CONDA_SHLVL=2\n",
      "FORCE_COLOR=1\n",
      "GIT_PAGER=cat\n",
      "HOME=/Users/Kauntey.Shah\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "JAVA_HOME=/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home\n",
      "JPY_PARENT_PID=91925\n",
      "JPY_SESSION_NAME=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook/XCS224W_Colab5.ipynb\n",
      "LC_CTYPE=en_GB.UTF-8\n",
      "LOGIN_SHELL=1\n",
      "LOGNAME=Kauntey.Shah\n",
      "MANPATH=/opt/homebrew/share/man::\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "OLDPWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PAGER=cat\n",
      "PATH='/Users/Kauntey.Shah/anaconda3/envs/xcs224w/bin:/Users/Kauntey.Shah/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion Tech Preview.app/Contents/Public:/usr/local/share/dotnet:/usr/local/munki:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home:/Users/Kauntey.Shah/Projects/development/tools/apache-maven-3.8.6/bin:/Users/Kauntey.Shah/Library/Application Support/Coursier/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home'\n",
      "PWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=2\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.Dud8dYkHAA/Listeners\n",
      "TERM=xterm-color\n",
      "TERMINAL_EMULATOR=JetBrains-JediTerm\n",
      "TERM_SESSION_ID=c3231f94-ef18-4397-b5a9-e30d8803575e\n",
      "TMPDIR=/var/folders/f1/qzsy2rls2q719_dqggb3l7fw0000gq/T/\n",
      "USER=Kauntey.Shah\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "_CE_CONDA=''\n",
      "_CE_M=''\n",
      "__CFBundleIdentifier=com.jetbrains.intellij.ce\n",
      "__CF_USER_TEXT_ENCODING=0x1F7:0:2\n",
      "__INTELLIJ_COMMAND_HISTFILE__=/Users/Kauntey.Shah/Library/Caches/JetBrains/IdeaIC2022.2/terminal/history/XCS224W-history2\n",
      "Requirement already satisfied: torch-geometric in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (2.29.0)\n",
      "Requirement already satisfied: pyparsing in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from requests->torch-geometric) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Kauntey.Shah/anaconda3/envs/XCS224W/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "COMMAND_MODE=unix2003\n",
      "CONDA_DEFAULT_ENV=xcs224w\n",
      "CONDA_EXE=/Users/Kauntey.Shah/anaconda3/bin/conda\n",
      "CONDA_PREFIX=/Users/Kauntey.Shah/anaconda3/envs/xcs224w\n",
      "CONDA_PREFIX_1=/Users/Kauntey.Shah/anaconda3\n",
      "CONDA_PROMPT_MODIFIER='(xcs224w) '\n",
      "CONDA_PYTHON_EXE=/Users/Kauntey.Shah/anaconda3/bin/python\n",
      "CONDA_SHLVL=2\n",
      "FORCE_COLOR=1\n",
      "GIT_PAGER=cat\n",
      "HOME=/Users/Kauntey.Shah\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "JAVA_HOME=/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home\n",
      "JPY_PARENT_PID=91925\n",
      "JPY_SESSION_NAME=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook/XCS224W_Colab5.ipynb\n",
      "LC_CTYPE=en_GB.UTF-8\n",
      "LOGIN_SHELL=1\n",
      "LOGNAME=Kauntey.Shah\n",
      "MANPATH=/opt/homebrew/share/man::\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "OLDPWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PAGER=cat\n",
      "PATH='/Users/Kauntey.Shah/anaconda3/envs/xcs224w/bin:/Users/Kauntey.Shah/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion Tech Preview.app/Contents/Public:/usr/local/share/dotnet:/usr/local/munki:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home:/Users/Kauntey.Shah/Projects/development/tools/apache-maven-3.8.6/bin:/Users/Kauntey.Shah/Library/Application Support/Coursier/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home'\n",
      "PWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=2\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.Dud8dYkHAA/Listeners\n",
      "TERM=xterm-color\n",
      "TERMINAL_EMULATOR=JetBrains-JediTerm\n",
      "TERM_SESSION_ID=c3231f94-ef18-4397-b5a9-e30d8803575e\n",
      "TMPDIR=/var/folders/f1/qzsy2rls2q719_dqggb3l7fw0000gq/T/\n",
      "USER=Kauntey.Shah\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "_CE_CONDA=''\n",
      "_CE_M=''\n",
      "__CFBundleIdentifier=com.jetbrains.intellij.ce\n",
      "__CF_USER_TEXT_ENCODING=0x1F7:0:2\n",
      "__INTELLIJ_COMMAND_HISTFILE__=/Users/Kauntey.Shah/Library/Caches/JetBrains/IdeaIC2022.2/terminal/history/XCS224W-history2\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "COMMAND_MODE=unix2003\n",
      "CONDA_DEFAULT_ENV=xcs224w\n",
      "CONDA_EXE=/Users/Kauntey.Shah/anaconda3/bin/conda\n",
      "CONDA_PREFIX=/Users/Kauntey.Shah/anaconda3/envs/xcs224w\n",
      "CONDA_PREFIX_1=/Users/Kauntey.Shah/anaconda3\n",
      "CONDA_PROMPT_MODIFIER='(xcs224w) '\n",
      "CONDA_PYTHON_EXE=/Users/Kauntey.Shah/anaconda3/bin/python\n",
      "CONDA_SHLVL=2\n",
      "FORCE_COLOR=1\n",
      "GIT_PAGER=cat\n",
      "HOME=/Users/Kauntey.Shah\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "JAVA_HOME=/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home\n",
      "JPY_PARENT_PID=91925\n",
      "JPY_SESSION_NAME=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook/XCS224W_Colab5.ipynb\n",
      "LC_CTYPE=en_GB.UTF-8\n",
      "LOGIN_SHELL=1\n",
      "LOGNAME=Kauntey.Shah\n",
      "MANPATH=/opt/homebrew/share/man::\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "OLDPWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PAGER=cat\n",
      "PATH='/Users/Kauntey.Shah/anaconda3/envs/xcs224w/bin:/Users/Kauntey.Shah/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion Tech Preview.app/Contents/Public:/usr/local/share/dotnet:/usr/local/munki:~/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home:/Users/Kauntey.Shah/Projects/development/tools/apache-maven-3.8.6/bin:/Users/Kauntey.Shah/Library/Application Support/Coursier/bin:/Users/Kauntey.Shah/Library/Java/JavaVirtualMachines/openjdk-19.0.2/Contents/Home'\n",
      "PWD=/Users/Kauntey.Shah/Projects/XCS224W/XCS224W-Colab5/Notebook\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=2\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.Dud8dYkHAA/Listeners\n",
      "TERM=xterm-color\n",
      "TERMINAL_EMULATOR=JetBrains-JediTerm\n",
      "TERM_SESSION_ID=c3231f94-ef18-4397-b5a9-e30d8803575e\n",
      "TMPDIR=/var/folders/f1/qzsy2rls2q719_dqggb3l7fw0000gq/T/\n",
      "USER=Kauntey.Shah\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "_CE_CONDA=''\n",
      "_CE_M=''\n",
      "__CFBundleIdentifier=com.jetbrains.intellij.ce\n",
      "__CF_USER_TEXT_ENCODING=0x1F7:0:2\n",
      "__INTELLIJ_COMMAND_HISTFILE__=/Users/Kauntey.Shah/Library/Caches/JetBrains/IdeaIC2022.2/terminal/history/XCS224W-history2\n"
     ]
    }
   ],
   "source": [
    "# Install torch geometric\n",
    "import os\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
    "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
    "  !pip install torch-geometric\n",
    "  !pip install -q ogb\n",
    "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PRfgbfTjCRD_",
    "outputId": "df8874ec-c447-48e8-85e1-ff5dbc209403",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFb2OAvOSn_O"
   },
   "source": [
    "# 1) Neighbor Sampling with Different Ratios\n",
    "\n",
    "We will implement our own simplified version of Neighbor Sampling using DeepSNAP and NetworkX. Then we will use our sampler to train models with different neighborhood sampling ratios and compare their performance.\n",
    "\n",
    "To make our experiments faster, we will use the Cora graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9U0F7bnSz9u"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUF4on-fSxcq",
    "outputId": "bd497e4d-5bde-4ac6-ace9-ea0378296de6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.graph import Graph\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  pyg_dataset = Planetoid('./tmp', \"Cora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qw6k-KdFTEYw"
   },
   "source": [
    "## GNN Model\n",
    "\n",
    "We use a simple GraphSage GNN model, which we provide to you below. Similar to in section one, notice the slightly different implementations of the forward method depending on the data `mode`. When `mode = \"batch\"` we use Neighbor sampling. Thus, the data parameter contains our graph's node features (`x`) and a list `edge_indices` containing the connectivity of each GNN layer (i.e. an edge_index for each layer, defining the bipartite neighborhood computation graph). \n",
    "\n",
    "**NOTE:** Refer to sections *Neighbor Sampling* and *PyTorch Geometric Neighbor Sampler* from Colab4 for a detailed overview of the Neighbor Sampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PvUlNi2TS09i",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args):\n",
    "        super(GNN, self).__init__()\n",
    "        self.dropout = args['dropout']\n",
    "        self.num_layers = args['num_layers']\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
    "        self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        for l in range(self.num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "        self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "\n",
    "        self.post_mp = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, mode=\"batch\"):\n",
    "        # Observe the difference between mode == \"batch\" and mode == \"all\".\n",
    "        # In mode == \"batch\" we pass in an edge index for each conv layer\n",
    "        # corresponding to that layer's bipartite graph structure.\n",
    "        if mode == \"batch\":\n",
    "            edge_indices, x = data\n",
    "            for i in range(len(self.convs) - 1):\n",
    "                edge_index = edge_indices[i]\n",
    "                x = self.convs[i](x, edge_index)\n",
    "                x = self.bns[i](x)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.convs[-1](x, edge_indices[len(self.convs) - 1])\n",
    "        else:\n",
    "            x, edge_index = data.node_feature, data.edge_index\n",
    "            for i in range(len(self.convs) - 1):\n",
    "                x = self.convs[i](x, edge_index)\n",
    "                x = self.bns[i](x)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.convs[-1](x, edge_index)\n",
    "        x = self.post_mp(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ulp1A3evcJ-I"
   },
   "source": [
    "## Implementing Neighbor Sampling\n",
    "\n",
    "Now let's take a stab at implementing our own basic version of Neighbor Sampling using DeepSNAP and NetworkX. To decompose the process, we will define several helper functions before finally defining our own `neighbor_sampling` function! \n",
    "\n",
    "**NOTE:** Before working through this section, we highly recommend reviewing sections `Neighbor Sampling` and `PyTorch Geometric Neighbor Sampler`. Specifically, it is important to understand how we explicitly define an `edge_index` for each GNN layer, representing the bipartite computation graph connecting the `target_nodes` that we are embedding for that layer to their relevant neighbors from the previous layer needed for message passing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWneVr3_Hj4n"
   },
   "source": [
    "## **Question 1.1a**: Implementing the `sample_neighbors` function. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1TZXvJhHjRK",
    "outputId": "659b85f5-0098-4b7a-9424-03392bf09642",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index fields: train_mask ignored.\n",
      "Index fields: test_mask ignored.\n",
      "Index fields: val_mask ignored.\n",
      "Neighbors with ratio = 1: {1632, 1090, 1315, 1316, 1093, 970, 2444, 2642, 1271, 927, 24, 2140, 2367}\n",
      "Neighbors with ratio = 0.3: {970, 2140, 2367}\n",
      "Ratio of sampled neighbors: 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "def sample_neighbors(nodes, G, ratio, all_nodes):\n",
    "    # TODO: Implement a function that takes as input a set of nodes, \n",
    "    # a NetworkX graph G, a neighbor sampling ratio, and a set containing all nodes \n",
    "    # and returns:\n",
    "    #   1. A set of the sampled nodes\n",
    "    #   2. A set union between `all_nodes` and the newly sampled neighbor nodes.\n",
    "    #      This allows us to track the nodes needed across all message passing layers.\n",
    "    #   3. The set of edges connecting the sampled neighboring nodes to our input\n",
    "    #      set of nodes. Represents a bi-partite graph between targets (nodes)\n",
    "    #      and source (neighbor) nodes.\n",
    "\n",
    "    neighbors = set()\n",
    "    edges = []\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~8-10 line of code)\n",
    "    ## Note:\n",
    "    ## 1. You will will need to sample neighbors from each node given to you in \n",
    "    ##    `nodes` list. \n",
    "    ##    Hint: Use graph `G` to assist in obtaining the neighbors of each node. \n",
    "    ## 2. The number of neighbors to be sampled based on the `ratio` parameter \n",
    "    ##    must be rounded **down** to get an integer value\n",
    "    ## 3. Randomly sample neighbors without replacement (i.e. the same neighbors \n",
    "    ##    should not be selected more than once for a given node) \n",
    "    ## 4. The neighbors are stored in a set data structure to ensure that duplicates\n",
    "    ##    are avoided.  This is useful as the set union will be taken with `all_nodes`. \n",
    "    ## 5. The edges list should contain all edges sampled in the form of a tuple\n",
    "    ##    of (neighbor, node)  \n",
    "    \n",
    "    for node in nodes:\n",
    "        n_list = list(nx.neighbors(G, node))\n",
    "        \n",
    "        # sample neighbors(ratio * number of neighbors)\n",
    "        num = int(len(n_list) * ratio)\n",
    "        if num > 0 :\n",
    "            random.shuffle(n_list)\n",
    "            n_list = n_list[:num]\n",
    "            for n in n_list:\n",
    "                neighbors.add(n)\n",
    "                edges.append((n, node))\n",
    "    ########################################## \n",
    "    return neighbors, neighbors.union(all_nodes), edges\n",
    "  \n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  graphs_train, _, _ = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "\n",
    "  nodes = [15, 16, 17]\n",
    "  neighbors_full, _, _ = sample_neighbors(nodes, graph_train.G, 1, set())\n",
    "  neighbors_sampled, _, _ = sample_neighbors(nodes, graph_train.G, 0.3, set())\n",
    "  print (\"Neighbors with ratio = 1:\", neighbors_full)\n",
    "  print (\"Neighbors with ratio = 0.3:\", neighbors_sampled)\n",
    "  # Note that this is not expected to be 0.3. Since we apply\n",
    "  # our sampling ratio for each node, the number of neighbors\n",
    "  # for each node may not evenly divide by the ratio   \n",
    "  print (\"Ratio of sampled neighbors:\", len(neighbors_sampled) / len(neighbors_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NKNh4TEJ8_p"
   },
   "source": [
    "## Tensor transformation and node relabeling helper functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H2PeBMJIJ9Tn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nodes_to_tensor(nodes):\n",
    "    \"\"\"\n",
    "      Transforms a set of nodes into a node index tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    node_label_index = torch.tensor(list(nodes), dtype=torch.long)\n",
    "    return node_label_index\n",
    "\n",
    "\n",
    "def edges_to_tensor(edges):\n",
    "    \"\"\"\n",
    "      Transforms a list of undirected edges into the corresponding PyG\n",
    "      edge_index tensor representation. Notice that we explicitly make\n",
    "      sure to include both edge directions.  \n",
    "    \"\"\"\n",
    "\n",
    "    edge_index = torch.tensor(list(edges), dtype=torch.long)\n",
    "    edge_index = torch.cat([edge_index, torch.flip(edge_index, [1])], dim=0)\n",
    "    edge_index = edge_index.permute(1, 0)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "def relabel(nodes, labeled_nodes, edges_list):\n",
    "    \"\"\"\n",
    "      Relabel nodes with 0 based indeces.\n",
    "      \n",
    "      During the sampling process, we are likely to sample a list of\n",
    "      non-continuous node ids. However, our GNN models rely on continuous\n",
    "      0 based indexing to index into the rows of our node features matrix \n",
    "      based on edges in the graph (edge_index)\n",
    "    \"\"\"\n",
    "\n",
    "    relabeled_edges_list = []\n",
    "    sorted_nodes = sorted(nodes)\n",
    "    node_mapping = {node : i for i, node in enumerate(sorted_nodes)}\n",
    "    for orig_edges in edges_list:\n",
    "        relabeled_edges = []\n",
    "        for edge in orig_edges:\n",
    "            relabeled_edges.append((node_mapping[edge[0]], node_mapping[edge[1]]))\n",
    "        relabeled_edges_list.append(relabeled_edges)\n",
    "    relabeled_labeled_nodes = [node_mapping[node] for node in labeled_nodes]\n",
    "    relabeled_nodes = [node_mapping[node] for node in nodes]\n",
    "\n",
    "    return relabeled_edges_list, relabeled_nodes, relabeled_labeled_nodes, sorted_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El-2h_ApOJYP"
   },
   "source": [
    "## **Question 1.1b**: Putting it all together - Implementing our own Neighbor Sampling function. (4 points)\n",
    "\n",
    "Now that we've developed a better understanding of what the Neighbor Sampling function does, we will implement our own version of it. Instead of choosing $H_k$ number of samples at each layer, we will use a ratio of the number of neigbors that a givn node has. Can you think of the pros and cons of using a ratio of the number of neighbors for a node at different layers?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LI4qHkE4cQOh",
    "outputId": "de449487-a8be-444e-9795-14d97773fc19",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index fields: train_mask ignored.\n",
      "Index fields: test_mask ignored.\n",
      "Index fields: val_mask ignored.\n",
      "Sampled 1889 nodes, 3036 edges, 140 labeled nodes\n"
     ]
    }
   ],
   "source": [
    "def neighbor_sampling(graph, K=2, ratios=(0.1, 0.1, 0.1)):\n",
    "    # TODO: Implement a function that performs Neighbor Sampling on an input\n",
    "    # graph G for a K layer GNN. Notice that len(ratios) = K + 1. Ratios[-1]\n",
    "    # determines size of our mini-batch (i.e. the number of labeled \n",
    "    # nodes we sample computation graphs for). \n",
    "\n",
    "    assert K + 1 == len(ratios)\n",
    "\n",
    "    labeled_nodes = graph.node_label_index.tolist()\n",
    "    random.shuffle(labeled_nodes)\n",
    "    num = int(len(labeled_nodes) * ratios[-1])\n",
    "    if num > 0:\n",
    "        labeled_nodes = labeled_nodes[:num]\n",
    "    nodes_list = [set(labeled_nodes)]\n",
    "    edges_list = []\n",
    "    all_nodes = labeled_nodes\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~4-6 line of code)\n",
    "    ## Note:\n",
    "    ## 1. Using your previously defined `sample_neighbors` function, build up the \n",
    "    ##    edges_list for our K layer network.\n",
    "    ## 2. nodes_list is a list where nodes_list[i] is set of nodes used for message\n",
    "    ##    passing in layer i+1 of our GNN (i.e. level i in our computation graph).\n",
    "    ##    Notice, nodes_list[-1] represents the target nodes we want to \n",
    "    ##    embedd in the mini-batch.\n",
    "    ## 3. edge_list is a list of the bi-partite edge conections between layers\n",
    "    ##    in the computation graph.\n",
    "    ## 4. all_nodes is used to track all the nodes needed for message passing.\n",
    "    ## 5. Remember in a GNN, information flows from the base of the computation\n",
    "    ##    graph to the root. How does this affect the way we add to the nodes_list \n",
    "    ##    and edge_list, as well as how we read from ratios (ratios[-1] \n",
    "    ##    represents the root nodes in our computation graph)?\n",
    "    for k in range(K):\n",
    "        nodes, all_nodes, edges = sample_neighbors(nodes_list[-1], graph.G, ratios[len(ratios) - k - 2], all_nodes)\n",
    "        nodes_list.append(nodes)\n",
    "        edges_list.append(edges)\n",
    "        \n",
    "    # reversing the lists\n",
    "    nodes_list.reverse()\n",
    "    edges_list.reverse()\n",
    "    #########################################\n",
    "\n",
    "    relabeled_edges_list, relabeled_all_nodes, relabeled_labeled_nodes, sorted_original_nodes = \\\n",
    "        relabel(all_nodes, labeled_nodes, edges_list)\n",
    "\n",
    "    node_index = nodes_to_tensor(sorted_original_nodes)\n",
    "    # All node features that will be used\n",
    "    node_feature = graph.node_feature[node_index]\n",
    "    edge_indices = [edges_to_tensor(edges) for edges in relabeled_edges_list]\n",
    "    node_label_index = nodes_to_tensor(relabeled_labeled_nodes)\n",
    "    orig_node_label_index = nodes_to_tensor(labeled_nodes)\n",
    "    log = \"Sampled {} nodes, {} edges, {} labeled nodes\"\n",
    "    print(log.format(node_feature.shape[0], edge_indices[0].shape[1] // 2, node_label_index.shape[0]))\n",
    "    return node_feature, edge_indices, node_label_index, orig_node_label_index\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # Need to define some basic test! Primarily to test whether they build \n",
    "  # in the correct reverse order. So ideally something like ratio = (0.3, 0.5, 0.8).\n",
    "  # Just need to check shapes.\n",
    "  \n",
    "  graphs_train, _, _ = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "\n",
    "  node_feature, edge_indices, node_label_index, _ = neighbor_sampling(graph_train, K=3, ratios=(0.5, 0.8, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooy6Hcf7TIhI"
   },
   "source": [
    "## Training and Testing\n",
    "\n",
    "Additionally, notice that node classification task on Cora is a semi-supervised classification task, here we keep all the labeled training nodes (140 nodes) by setting the last ratio to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iSmZhpzPTGPY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_graphs, val_graphs, args, model, optimizer, mode=\"batch\"):\n",
    "    best_val = 0\n",
    "    best_model = None\n",
    "    accs = []\n",
    "    graph_train = train_graphs[0]\n",
    "    graph_train.to(args['device'])\n",
    "    for epoch in range(1, 1 + args['epochs']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if mode == \"batch\":\n",
    "            node_feature, edge_indices, node_label_index, orig_node_index = neighbor_sampling(graph_train, args['num_layers'], args['ratios'])\n",
    "            node_feature = node_feature.to(args['device'])\n",
    "            node_label_index = node_label_index.to(args['device'])\n",
    "            for i in range(len(edge_indices)):\n",
    "                edge_indices[i] = edge_indices[i].to(args['device'])\n",
    "            pred = model([edge_indices, node_feature])\n",
    "            pred = pred[node_label_index]\n",
    "            label = graph_train.node_label[orig_node_index]\n",
    "        elif mode == \"community\":\n",
    "            graph = random.choice(train_graphs)\n",
    "            graph = graph.to(args['device'])\n",
    "            pred = model(graph, mode=\"all\")\n",
    "            pred = pred[graph.node_label_index]\n",
    "            label = graph.node_label[graph.node_label_index]\n",
    "        else:\n",
    "            pred = model(graph_train, mode=\"all\")\n",
    "            label = graph_train.node_label\n",
    "            pred = pred[graph_train.node_label_index]\n",
    "        loss = F.nll_loss(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc, val_acc, test_acc = test(val_graphs, model)\n",
    "        accs.append((train_acc, val_acc, test_acc))\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_acc:.2f}%, '\n",
    "              f'Valid: {100 * val_acc:.2f}% '\n",
    "              f'Test: {100 * test_acc:.2f}%')\n",
    "    return best_model, accs\n",
    "\n",
    "def test(graphs, model, save_model_results=False, batch_type=\"batch\", title=None):\n",
    "    model.eval()\n",
    "    accs = []\n",
    "  \n",
    "    for graph in graphs:\n",
    "        graph = graph.to(args['device'])\n",
    "        pred = model(graph, mode=\"all\")\n",
    "        label = graph.node_label\n",
    "        pred = pred[graph.node_label_index].max(1)[1]\n",
    "        acc = pred.eq(label).sum().item()\n",
    "        acc /= len(label)\n",
    "        accs.append(acc)\n",
    "    \n",
    "    if save_model_results:\n",
    "      print (\"Saving Model Predictions for Model:\", batch_type, title)\n",
    "\n",
    "      data = {}\n",
    "      # The last dataset we test is the test graph\n",
    "      data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "      data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "      df = pd.DataFrame(data=data)\n",
    "      # Save locally as csv\n",
    "      file_name = 'CORA_Node_' + batch_type\n",
    "      if title is not None:\n",
    "        file_name = file_name + \"_\" + title\n",
    "\n",
    "      df.to_csv(file_name + '.csv', sep=',', index=False)\n",
    "\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HV7i0v0ETKzf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'dropout': 0.5,\n",
    "    'num_layers': 2,\n",
    "    'hidden_size': 64,\n",
    "    'lr': 0.005,\n",
    "    'epochs': 50,\n",
    "    'ratios': (0.8, 0.8, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kfiKId8-iBj1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=224):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLpRYKbnTQnj"
   },
   "source": [
    "## Full-Batch Training\n",
    "\n",
    "As a baseline, we train our GNN model over the entire graph without any Neighbor Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMGGjbJBTOo1",
    "outputId": "9d5c3068-1da9-4453-f1c5-332ffec090e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index fields: train_mask ignored.\n",
      "Index fields: test_mask ignored.\n",
      "Index fields: val_mask ignored.\n",
      "Epoch: 01, Loss: 1.9927, Train: 65.00%, Valid: 31.00% Test: 36.20%\n",
      "Epoch: 02, Loss: 1.0889, Train: 97.14%, Valid: 53.20% Test: 57.70%\n",
      "Epoch: 03, Loss: 0.6262, Train: 99.29%, Valid: 66.80% Test: 67.80%\n",
      "Epoch: 04, Loss: 0.2879, Train: 100.00%, Valid: 72.20% Test: 72.70%\n",
      "Epoch: 05, Loss: 0.1308, Train: 100.00%, Valid: 74.20% Test: 73.50%\n",
      "Epoch: 06, Loss: 0.0578, Train: 100.00%, Valid: 74.40% Test: 74.80%\n",
      "Epoch: 07, Loss: 0.0459, Train: 100.00%, Valid: 74.40% Test: 74.40%\n",
      "Epoch: 08, Loss: 0.0291, Train: 100.00%, Valid: 75.40% Test: 75.00%\n",
      "Epoch: 09, Loss: 0.0125, Train: 100.00%, Valid: 74.60% Test: 74.50%\n",
      "Epoch: 10, Loss: 0.0070, Train: 100.00%, Valid: 74.40% Test: 74.50%\n",
      "Epoch: 11, Loss: 0.0105, Train: 100.00%, Valid: 74.40% Test: 74.70%\n",
      "Epoch: 12, Loss: 0.0043, Train: 100.00%, Valid: 74.40% Test: 75.00%\n",
      "Epoch: 13, Loss: 0.0024, Train: 100.00%, Valid: 74.20% Test: 74.90%\n",
      "Epoch: 14, Loss: 0.0096, Train: 100.00%, Valid: 73.80% Test: 74.40%\n",
      "Epoch: 15, Loss: 0.0008, Train: 100.00%, Valid: 73.60% Test: 74.20%\n",
      "Epoch: 16, Loss: 0.0008, Train: 100.00%, Valid: 73.60% Test: 74.40%\n",
      "Epoch: 17, Loss: 0.0016, Train: 100.00%, Valid: 73.40% Test: 74.30%\n",
      "Epoch: 18, Loss: 0.0005, Train: 100.00%, Valid: 73.40% Test: 74.20%\n",
      "Epoch: 19, Loss: 0.0006, Train: 100.00%, Valid: 73.20% Test: 74.00%\n",
      "Epoch: 20, Loss: 0.0015, Train: 100.00%, Valid: 73.40% Test: 74.10%\n",
      "Epoch: 21, Loss: 0.0002, Train: 100.00%, Valid: 73.00% Test: 73.90%\n",
      "Epoch: 22, Loss: 0.0009, Train: 100.00%, Valid: 73.00% Test: 73.90%\n",
      "Epoch: 23, Loss: 0.0001, Train: 100.00%, Valid: 73.00% Test: 73.90%\n",
      "Epoch: 24, Loss: 0.0017, Train: 100.00%, Valid: 72.60% Test: 73.90%\n",
      "Epoch: 25, Loss: 0.0001, Train: 100.00%, Valid: 72.40% Test: 74.00%\n",
      "Epoch: 26, Loss: 0.0013, Train: 100.00%, Valid: 72.40% Test: 74.10%\n",
      "Epoch: 27, Loss: 0.0002, Train: 100.00%, Valid: 72.20% Test: 74.00%\n",
      "Epoch: 28, Loss: 0.0002, Train: 100.00%, Valid: 72.00% Test: 74.10%\n",
      "Epoch: 29, Loss: 0.0001, Train: 100.00%, Valid: 72.20% Test: 74.30%\n",
      "Epoch: 30, Loss: 0.0000, Train: 100.00%, Valid: 72.00% Test: 74.30%\n",
      "Epoch: 31, Loss: 0.0002, Train: 100.00%, Valid: 71.80% Test: 74.50%\n",
      "Epoch: 32, Loss: 0.0002, Train: 100.00%, Valid: 71.80% Test: 74.40%\n",
      "Epoch: 33, Loss: 0.0007, Train: 100.00%, Valid: 72.00% Test: 74.50%\n",
      "Epoch: 34, Loss: 0.0001, Train: 100.00%, Valid: 72.00% Test: 74.50%\n",
      "Epoch: 35, Loss: 0.0001, Train: 100.00%, Valid: 72.00% Test: 74.50%\n",
      "Epoch: 36, Loss: 0.0002, Train: 100.00%, Valid: 72.00% Test: 74.40%\n",
      "Epoch: 37, Loss: 0.0021, Train: 100.00%, Valid: 72.00% Test: 74.40%\n",
      "Epoch: 38, Loss: 0.0000, Train: 100.00%, Valid: 72.20% Test: 74.40%\n",
      "Epoch: 39, Loss: 0.0001, Train: 100.00%, Valid: 72.20% Test: 74.40%\n",
      "Epoch: 40, Loss: 0.0001, Train: 100.00%, Valid: 72.40% Test: 74.40%\n",
      "Epoch: 41, Loss: 0.0010, Train: 100.00%, Valid: 72.40% Test: 74.10%\n",
      "Epoch: 42, Loss: 0.0001, Train: 100.00%, Valid: 72.40% Test: 74.20%\n",
      "Epoch: 43, Loss: 0.0015, Train: 100.00%, Valid: 72.40% Test: 74.30%\n",
      "Epoch: 44, Loss: 0.0001, Train: 100.00%, Valid: 72.40% Test: 74.30%\n",
      "Epoch: 45, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 74.30%\n",
      "Epoch: 46, Loss: 0.0000, Train: 100.00%, Valid: 72.40% Test: 74.30%\n",
      "Epoch: 47, Loss: 0.0001, Train: 100.00%, Valid: 72.40% Test: 74.50%\n",
      "Epoch: 48, Loss: 0.0005, Train: 100.00%, Valid: 72.40% Test: 74.50%\n",
      "Epoch: 49, Loss: 0.0002, Train: 100.00%, Valid: 72.40% Test: 74.40%\n",
      "Epoch: 50, Loss: 0.0001, Train: 100.00%, Valid: 72.40% Test: 74.40%\n",
      "Best model: Train: 100.00%, Valid: 75.40% Test: 75.00%\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "\n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "\n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  graphs = [graph_train, graph_val, graph_test]\n",
    "  all_best_model, all_accs = train(graphs, graphs, args, model, optimizer, mode=\"all\")\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], all_best_model)\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWkGiwB6Thr4"
   },
   "source": [
    "## **Question 1.2a:** What is the maximum test accuracy using samping ratios = (0.7, 0.9, 1)? (12 points)\n",
    "\n",
    "Running the cell below will show the results of your best model and save your best model's predictions to a file named CORA_Node_batch_(0.7, 0.9, 1).csv'.\n",
    "\n",
    "As we have seen before you can view this file by clicking on the Folder icon on the left side pannel. When you sumbit your assignment, you will have to download this file and attatch it to your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWusJ9u3Tfhv",
    "outputId": "000b9140-e038-48a6-f79e-f02a4c4c1e98",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index fields: train_mask ignored.\n",
      "Index fields: test_mask ignored.\n",
      "Index fields: val_mask ignored.\n",
      "Sampled 1282 nodes, 1825 edges, 140 labeled nodes\n",
      "Epoch: 01, Loss: 1.9630, Train: 50.00%, Valid: 20.60% Test: 27.10%\n",
      "Sampled 1247 nodes, 1779 edges, 140 labeled nodes\n",
      "Epoch: 02, Loss: 1.3010, Train: 90.71%, Valid: 48.00% Test: 53.70%\n",
      "Sampled 1267 nodes, 1782 edges, 140 labeled nodes\n",
      "Epoch: 03, Loss: 0.8862, Train: 95.71%, Valid: 63.40% Test: 68.20%\n",
      "Sampled 1250 nodes, 1781 edges, 140 labeled nodes\n",
      "Epoch: 04, Loss: 0.5751, Train: 96.43%, Valid: 69.60% Test: 72.70%\n",
      "Sampled 1260 nodes, 1808 edges, 140 labeled nodes\n",
      "Epoch: 05, Loss: 0.3981, Train: 97.86%, Valid: 72.00% Test: 74.50%\n",
      "Sampled 1277 nodes, 1821 edges, 140 labeled nodes\n",
      "Epoch: 06, Loss: 0.2507, Train: 97.86%, Valid: 72.60% Test: 76.20%\n",
      "Sampled 1284 nodes, 1801 edges, 140 labeled nodes\n",
      "Epoch: 07, Loss: 0.1551, Train: 98.57%, Valid: 72.60% Test: 75.80%\n",
      "Sampled 1274 nodes, 1834 edges, 140 labeled nodes\n",
      "Epoch: 08, Loss: 0.1051, Train: 100.00%, Valid: 73.00% Test: 76.20%\n",
      "Sampled 1273 nodes, 1798 edges, 140 labeled nodes\n",
      "Epoch: 09, Loss: 0.0777, Train: 100.00%, Valid: 74.00% Test: 76.40%\n",
      "Sampled 1223 nodes, 1707 edges, 140 labeled nodes\n",
      "Epoch: 10, Loss: 0.0501, Train: 100.00%, Valid: 74.40% Test: 76.40%\n",
      "Sampled 1241 nodes, 1767 edges, 140 labeled nodes\n",
      "Epoch: 11, Loss: 0.0517, Train: 100.00%, Valid: 74.00% Test: 76.40%\n",
      "Sampled 1262 nodes, 1794 edges, 140 labeled nodes\n",
      "Epoch: 12, Loss: 0.0336, Train: 100.00%, Valid: 74.00% Test: 76.40%\n",
      "Sampled 1253 nodes, 1818 edges, 140 labeled nodes\n",
      "Epoch: 13, Loss: 0.0116, Train: 100.00%, Valid: 74.60% Test: 75.90%\n",
      "Sampled 1247 nodes, 1757 edges, 140 labeled nodes\n",
      "Epoch: 14, Loss: 0.0134, Train: 100.00%, Valid: 74.60% Test: 76.00%\n",
      "Sampled 1248 nodes, 1778 edges, 140 labeled nodes\n",
      "Epoch: 15, Loss: 0.0182, Train: 100.00%, Valid: 74.40% Test: 76.30%\n",
      "Sampled 1258 nodes, 1778 edges, 140 labeled nodes\n",
      "Epoch: 16, Loss: 0.0134, Train: 100.00%, Valid: 74.40% Test: 76.30%\n",
      "Sampled 1266 nodes, 1788 edges, 140 labeled nodes\n",
      "Epoch: 17, Loss: 0.0055, Train: 100.00%, Valid: 74.40% Test: 76.40%\n",
      "Sampled 1262 nodes, 1779 edges, 140 labeled nodes\n",
      "Epoch: 18, Loss: 0.0160, Train: 100.00%, Valid: 74.60% Test: 76.50%\n",
      "Sampled 1271 nodes, 1830 edges, 140 labeled nodes\n",
      "Epoch: 19, Loss: 0.0112, Train: 100.00%, Valid: 74.60% Test: 76.30%\n",
      "Sampled 1228 nodes, 1771 edges, 140 labeled nodes\n",
      "Epoch: 20, Loss: 0.0109, Train: 100.00%, Valid: 74.20% Test: 76.30%\n",
      "Sampled 1277 nodes, 1830 edges, 140 labeled nodes\n",
      "Epoch: 21, Loss: 0.0037, Train: 100.00%, Valid: 74.20% Test: 75.90%\n",
      "Sampled 1236 nodes, 1756 edges, 140 labeled nodes\n",
      "Epoch: 22, Loss: 0.0043, Train: 100.00%, Valid: 74.20% Test: 75.60%\n",
      "Sampled 1264 nodes, 1786 edges, 140 labeled nodes\n",
      "Epoch: 23, Loss: 0.0023, Train: 100.00%, Valid: 73.80% Test: 75.40%\n",
      "Sampled 1291 nodes, 1841 edges, 140 labeled nodes\n",
      "Epoch: 24, Loss: 0.0009, Train: 100.00%, Valid: 73.60% Test: 75.50%\n",
      "Sampled 1264 nodes, 1827 edges, 140 labeled nodes\n",
      "Epoch: 25, Loss: 0.0141, Train: 100.00%, Valid: 73.60% Test: 75.40%\n",
      "Sampled 1261 nodes, 1772 edges, 140 labeled nodes\n",
      "Epoch: 26, Loss: 0.0051, Train: 100.00%, Valid: 73.40% Test: 75.40%\n",
      "Sampled 1274 nodes, 1829 edges, 140 labeled nodes\n",
      "Epoch: 27, Loss: 0.0006, Train: 100.00%, Valid: 73.20% Test: 75.20%\n",
      "Sampled 1267 nodes, 1802 edges, 140 labeled nodes\n",
      "Epoch: 28, Loss: 0.0013, Train: 100.00%, Valid: 72.80% Test: 75.00%\n",
      "Sampled 1279 nodes, 1787 edges, 140 labeled nodes\n",
      "Epoch: 29, Loss: 0.0020, Train: 100.00%, Valid: 73.00% Test: 75.00%\n",
      "Sampled 1274 nodes, 1831 edges, 140 labeled nodes\n",
      "Epoch: 30, Loss: 0.0075, Train: 100.00%, Valid: 73.00% Test: 74.80%\n",
      "Sampled 1231 nodes, 1766 edges, 140 labeled nodes\n",
      "Epoch: 31, Loss: 0.0008, Train: 100.00%, Valid: 73.00% Test: 74.70%\n",
      "Sampled 1262 nodes, 1832 edges, 140 labeled nodes\n",
      "Epoch: 32, Loss: 0.0010, Train: 100.00%, Valid: 73.20% Test: 74.30%\n",
      "Sampled 1240 nodes, 1766 edges, 140 labeled nodes\n",
      "Epoch: 33, Loss: 0.0015, Train: 100.00%, Valid: 72.80% Test: 74.30%\n",
      "Sampled 1265 nodes, 1819 edges, 140 labeled nodes\n",
      "Epoch: 34, Loss: 0.0012, Train: 100.00%, Valid: 72.80% Test: 74.40%\n",
      "Sampled 1237 nodes, 1768 edges, 140 labeled nodes\n",
      "Epoch: 35, Loss: 0.0105, Train: 100.00%, Valid: 72.80% Test: 74.50%\n",
      "Sampled 1256 nodes, 1784 edges, 140 labeled nodes\n",
      "Epoch: 36, Loss: 0.0099, Train: 100.00%, Valid: 72.60% Test: 74.30%\n",
      "Sampled 1267 nodes, 1836 edges, 140 labeled nodes\n",
      "Epoch: 37, Loss: 0.0024, Train: 100.00%, Valid: 72.40% Test: 74.40%\n",
      "Sampled 1265 nodes, 1778 edges, 140 labeled nodes\n",
      "Epoch: 38, Loss: 0.0003, Train: 100.00%, Valid: 72.40% Test: 74.30%\n",
      "Sampled 1273 nodes, 1798 edges, 140 labeled nodes\n",
      "Epoch: 39, Loss: 0.0007, Train: 100.00%, Valid: 72.20% Test: 74.50%\n",
      "Sampled 1203 nodes, 1717 edges, 140 labeled nodes\n",
      "Epoch: 40, Loss: 0.0045, Train: 100.00%, Valid: 72.40% Test: 74.40%\n",
      "Sampled 1250 nodes, 1786 edges, 140 labeled nodes\n",
      "Epoch: 41, Loss: 0.0011, Train: 100.00%, Valid: 72.20% Test: 74.30%\n",
      "Sampled 1280 nodes, 1816 edges, 140 labeled nodes\n",
      "Epoch: 42, Loss: 0.0045, Train: 100.00%, Valid: 72.40% Test: 74.60%\n",
      "Sampled 1245 nodes, 1777 edges, 140 labeled nodes\n",
      "Epoch: 43, Loss: 0.0005, Train: 100.00%, Valid: 72.60% Test: 74.50%\n",
      "Sampled 1294 nodes, 1838 edges, 140 labeled nodes\n",
      "Epoch: 44, Loss: 0.0005, Train: 100.00%, Valid: 72.80% Test: 74.30%\n",
      "Sampled 1252 nodes, 1817 edges, 140 labeled nodes\n",
      "Epoch: 45, Loss: 0.0003, Train: 100.00%, Valid: 73.00% Test: 74.30%\n",
      "Sampled 1268 nodes, 1827 edges, 140 labeled nodes\n",
      "Epoch: 46, Loss: 0.0003, Train: 100.00%, Valid: 73.00% Test: 74.30%\n",
      "Sampled 1248 nodes, 1807 edges, 140 labeled nodes\n",
      "Epoch: 47, Loss: 0.0020, Train: 100.00%, Valid: 73.00% Test: 74.50%\n",
      "Sampled 1197 nodes, 1749 edges, 140 labeled nodes\n",
      "Epoch: 48, Loss: 0.0003, Train: 100.00%, Valid: 73.40% Test: 74.50%\n",
      "Sampled 1260 nodes, 1800 edges, 140 labeled nodes\n",
      "Epoch: 49, Loss: 0.0006, Train: 100.00%, Valid: 73.40% Test: 74.30%\n",
      "Sampled 1250 nodes, 1764 edges, 140 labeled nodes\n",
      "Epoch: 50, Loss: 0.0002, Train: 100.00%, Valid: 73.40% Test: 74.40%\n",
      "Saving Model Predictions for Model: batch (0.7,0.9,1)\n",
      "Best model: Train: 100.00%, Valid: 74.60% Test: 75.90%\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  args['ratios'] = (0.7, 0.9, 1)\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "\n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "\n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "    \n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  graphs = [graph_train, graph_val, graph_test]\n",
    "  batch_best_model, batch_accs = train(graphs, graphs, args, model, optimizer)\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], batch_best_model, save_model_results=True, batch_type=\"batch\", title=\"(0.7,0.9,1)\")\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_FjkNHDT4c6"
   },
   "source": [
    "## **Question 1.2b:** What is the maximum test accuracy using samping ratios = (0.3, 0.5, 1)? (12 points)\n",
    "\n",
    "Running the cell below will show the results of your best model and save your best model's predictions to a file named CORA_Node_batch_(0.3, 0.5, 1).csv'.\n",
    "\n",
    "As we have seen before you can view this file by clicking on the Folder icon on the left side pannel. When you submit your assignment, you will have to download this file and attach it to your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "booJ6DASTjO4",
    "outputId": "27f531bc-3d33-4f94-c1b7-d88bf4c1ffbe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index fields: train_mask ignored.\n",
      "Index fields: test_mask ignored.\n",
      "Index fields: val_mask ignored.\n",
      "Sampled 645 nodes, 426 edges, 140 labeled nodes\n",
      "Epoch: 01, Loss: 2.0136, Train: 43.57%, Valid: 18.80% Test: 24.40%\n",
      "Sampled 652 nodes, 452 edges, 140 labeled nodes\n",
      "Epoch: 02, Loss: 1.5003, Train: 77.86%, Valid: 33.80% Test: 38.10%\n",
      "Sampled 692 nodes, 491 edges, 140 labeled nodes\n",
      "Epoch: 03, Loss: 1.1036, Train: 90.00%, Valid: 48.60% Test: 54.00%\n",
      "Sampled 656 nodes, 435 edges, 140 labeled nodes\n",
      "Epoch: 04, Loss: 0.8321, Train: 95.71%, Valid: 62.60% Test: 64.60%\n",
      "Sampled 678 nodes, 475 edges, 140 labeled nodes\n",
      "Epoch: 05, Loss: 0.5980, Train: 97.86%, Valid: 68.80% Test: 71.40%\n",
      "Sampled 659 nodes, 437 edges, 140 labeled nodes\n",
      "Epoch: 06, Loss: 0.4453, Train: 97.86%, Valid: 71.00% Test: 74.30%\n",
      "Sampled 649 nodes, 444 edges, 140 labeled nodes\n",
      "Epoch: 07, Loss: 0.2941, Train: 99.29%, Valid: 73.20% Test: 75.50%\n",
      "Sampled 665 nodes, 447 edges, 140 labeled nodes\n",
      "Epoch: 08, Loss: 0.2043, Train: 99.29%, Valid: 73.20% Test: 76.00%\n",
      "Sampled 706 nodes, 487 edges, 140 labeled nodes\n",
      "Epoch: 09, Loss: 0.1719, Train: 99.29%, Valid: 73.40% Test: 76.00%\n",
      "Sampled 645 nodes, 412 edges, 140 labeled nodes\n",
      "Epoch: 10, Loss: 0.1142, Train: 99.29%, Valid: 73.40% Test: 77.00%\n",
      "Sampled 656 nodes, 420 edges, 140 labeled nodes\n",
      "Epoch: 11, Loss: 0.0587, Train: 100.00%, Valid: 73.60% Test: 76.70%\n",
      "Sampled 664 nodes, 448 edges, 140 labeled nodes\n",
      "Epoch: 12, Loss: 0.0619, Train: 100.00%, Valid: 73.40% Test: 76.50%\n",
      "Sampled 665 nodes, 439 edges, 140 labeled nodes\n",
      "Epoch: 13, Loss: 0.0374, Train: 100.00%, Valid: 74.00% Test: 75.90%\n",
      "Sampled 679 nodes, 459 edges, 140 labeled nodes\n",
      "Epoch: 14, Loss: 0.0225, Train: 100.00%, Valid: 74.20% Test: 76.10%\n",
      "Sampled 635 nodes, 440 edges, 140 labeled nodes\n",
      "Epoch: 15, Loss: 0.0289, Train: 100.00%, Valid: 73.60% Test: 75.90%\n",
      "Sampled 675 nodes, 466 edges, 140 labeled nodes\n",
      "Epoch: 16, Loss: 0.0134, Train: 100.00%, Valid: 74.00% Test: 75.50%\n",
      "Sampled 648 nodes, 421 edges, 140 labeled nodes\n",
      "Epoch: 17, Loss: 0.0232, Train: 100.00%, Valid: 73.60% Test: 75.50%\n",
      "Sampled 663 nodes, 422 edges, 140 labeled nodes\n",
      "Epoch: 18, Loss: 0.0084, Train: 100.00%, Valid: 74.00% Test: 75.00%\n",
      "Sampled 665 nodes, 468 edges, 140 labeled nodes\n",
      "Epoch: 19, Loss: 0.0258, Train: 100.00%, Valid: 73.80% Test: 75.00%\n",
      "Sampled 673 nodes, 453 edges, 140 labeled nodes\n",
      "Epoch: 20, Loss: 0.0060, Train: 100.00%, Valid: 73.20% Test: 75.20%\n",
      "Sampled 642 nodes, 434 edges, 140 labeled nodes\n",
      "Epoch: 21, Loss: 0.0059, Train: 100.00%, Valid: 73.40% Test: 74.70%\n",
      "Sampled 673 nodes, 474 edges, 140 labeled nodes\n",
      "Epoch: 22, Loss: 0.0133, Train: 100.00%, Valid: 73.20% Test: 74.60%\n",
      "Sampled 655 nodes, 454 edges, 140 labeled nodes\n",
      "Epoch: 23, Loss: 0.0027, Train: 100.00%, Valid: 73.00% Test: 74.70%\n",
      "Sampled 654 nodes, 441 edges, 140 labeled nodes\n",
      "Epoch: 24, Loss: 0.0018, Train: 100.00%, Valid: 72.80% Test: 74.80%\n",
      "Sampled 658 nodes, 459 edges, 140 labeled nodes\n",
      "Epoch: 25, Loss: 0.0093, Train: 100.00%, Valid: 72.60% Test: 74.80%\n",
      "Sampled 662 nodes, 445 edges, 140 labeled nodes\n",
      "Epoch: 26, Loss: 0.0021, Train: 100.00%, Valid: 72.20% Test: 74.60%\n",
      "Sampled 643 nodes, 436 edges, 140 labeled nodes\n",
      "Epoch: 27, Loss: 0.0042, Train: 100.00%, Valid: 72.20% Test: 74.40%\n",
      "Sampled 665 nodes, 432 edges, 140 labeled nodes\n",
      "Epoch: 28, Loss: 0.0049, Train: 100.00%, Valid: 71.60% Test: 74.70%\n",
      "Sampled 646 nodes, 437 edges, 140 labeled nodes\n",
      "Epoch: 29, Loss: 0.0210, Train: 100.00%, Valid: 72.00% Test: 74.80%\n",
      "Sampled 688 nodes, 474 edges, 140 labeled nodes\n",
      "Epoch: 30, Loss: 0.0021, Train: 100.00%, Valid: 71.80% Test: 74.70%\n",
      "Sampled 695 nodes, 471 edges, 140 labeled nodes\n",
      "Epoch: 31, Loss: 0.0077, Train: 100.00%, Valid: 71.60% Test: 74.50%\n",
      "Sampled 671 nodes, 459 edges, 140 labeled nodes\n",
      "Epoch: 32, Loss: 0.0044, Train: 100.00%, Valid: 72.00% Test: 74.00%\n",
      "Sampled 630 nodes, 411 edges, 140 labeled nodes\n",
      "Epoch: 33, Loss: 0.0009, Train: 100.00%, Valid: 72.00% Test: 74.10%\n",
      "Sampled 671 nodes, 484 edges, 140 labeled nodes\n",
      "Epoch: 34, Loss: 0.0070, Train: 100.00%, Valid: 71.80% Test: 74.00%\n",
      "Sampled 676 nodes, 453 edges, 140 labeled nodes\n",
      "Epoch: 35, Loss: 0.0033, Train: 100.00%, Valid: 72.00% Test: 74.10%\n",
      "Sampled 655 nodes, 460 edges, 140 labeled nodes\n",
      "Epoch: 36, Loss: 0.0004, Train: 100.00%, Valid: 72.00% Test: 74.10%\n",
      "Sampled 699 nodes, 457 edges, 140 labeled nodes\n",
      "Epoch: 37, Loss: 0.0104, Train: 100.00%, Valid: 72.20% Test: 74.10%\n",
      "Sampled 682 nodes, 478 edges, 140 labeled nodes\n",
      "Epoch: 38, Loss: 0.0012, Train: 100.00%, Valid: 72.20% Test: 73.90%\n",
      "Sampled 673 nodes, 452 edges, 140 labeled nodes\n",
      "Epoch: 39, Loss: 0.0029, Train: 100.00%, Valid: 72.20% Test: 73.70%\n",
      "Sampled 647 nodes, 408 edges, 140 labeled nodes\n",
      "Epoch: 40, Loss: 0.0168, Train: 100.00%, Valid: 72.00% Test: 73.80%\n",
      "Sampled 647 nodes, 433 edges, 140 labeled nodes\n",
      "Epoch: 41, Loss: 0.0014, Train: 100.00%, Valid: 72.20% Test: 73.50%\n",
      "Sampled 642 nodes, 432 edges, 140 labeled nodes\n",
      "Epoch: 42, Loss: 0.0019, Train: 100.00%, Valid: 72.00% Test: 73.40%\n",
      "Sampled 684 nodes, 469 edges, 140 labeled nodes\n",
      "Epoch: 43, Loss: 0.0018, Train: 100.00%, Valid: 72.00% Test: 73.40%\n",
      "Sampled 656 nodes, 445 edges, 140 labeled nodes\n",
      "Epoch: 44, Loss: 0.0005, Train: 100.00%, Valid: 72.20% Test: 73.40%\n",
      "Sampled 672 nodes, 445 edges, 140 labeled nodes\n",
      "Epoch: 45, Loss: 0.0008, Train: 100.00%, Valid: 72.20% Test: 73.40%\n",
      "Sampled 648 nodes, 435 edges, 140 labeled nodes\n",
      "Epoch: 46, Loss: 0.0007, Train: 100.00%, Valid: 72.20% Test: 73.60%\n",
      "Sampled 679 nodes, 449 edges, 140 labeled nodes\n",
      "Epoch: 47, Loss: 0.0017, Train: 100.00%, Valid: 72.40% Test: 73.50%\n",
      "Sampled 642 nodes, 432 edges, 140 labeled nodes\n",
      "Epoch: 48, Loss: 0.0024, Train: 100.00%, Valid: 72.40% Test: 73.40%\n",
      "Sampled 639 nodes, 420 edges, 140 labeled nodes\n",
      "Epoch: 49, Loss: 0.0069, Train: 100.00%, Valid: 72.60% Test: 73.60%\n",
      "Sampled 663 nodes, 446 edges, 140 labeled nodes\n",
      "Epoch: 50, Loss: 0.0233, Train: 100.00%, Valid: 72.60% Test: 73.60%\n",
      "Saving Model Predictions for Model: batch (0.3,0.5,1)\n",
      "Best model: Train: 100.00%, Valid: 74.20% Test: 76.10%\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  # Change the ratio to 0.3\n",
    "  args['ratios'] = (0.3, 0.5, 1)\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "\n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "  \n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  graphs = [graph_train, graph_val, graph_test]\n",
    "  batch_best_model, batch_accs_1 = train(graphs, graphs, args, model, optimizer)\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], batch_best_model, save_model_results=True, batch_type=\"batch\", title=\"(0.3,0.5,1)\")\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EePAvNlGUM2K"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "7etNAkXAT55d",
    "outputId": "de3e56a1-08f2-41d4-bc11-1c454fc2f85c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  batch_results = np.array(batch_accs)\n",
    "  batch_results_1 = np.array(batch_accs_1)\n",
    "  all_results = np.array(all_accs)\n",
    "\n",
    "  x = np.arange(1, 51)\n",
    "\n",
    "  plt.figure(figsize=(9, 7))\n",
    "\n",
    "  plt.plot(x, batch_results[:, 0], label=\"Batch 0.8 Train\")\n",
    "  plt.plot(x, batch_results[:, 1], label=\"Batch 0.8 Validation\")\n",
    "  plt.plot(x, batch_results[:, 2], label=\"Batch 0.8 Test\")\n",
    "  plt.plot(x, batch_results_1[:, 0], label=\"Batch 0.3 Train\")\n",
    "  plt.plot(x, batch_results_1[:, 1], label=\"Batch 0.3 Validation\")\n",
    "  plt.plot(x, batch_results_1[:, 2], label=\"Batch 0.3 Test\")\n",
    "  plt.plot(x, all_results[:, 0], label=\"All Train\")\n",
    "  plt.plot(x, all_results[:, 1], label=\"All Validation\")\n",
    "  plt.plot(x, all_results[:, 2], label=\"All Test\")\n",
    "  plt.title('Model Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkA7-0groq7q"
   },
   "source": [
    "**NOTE:** We always evaluate accuracy in full-batch mode. Namely, only during training do we use neighborhood sub-sampling. We do this for a couple reason: 1) fairness of comparison, 2) we worry most about computational cost during training as compared to evaluation, and 3) during the inference phase we want to leverage as much neighborhood information as possible!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iee0U8KGURc8"
   },
   "source": [
    "# 2) Cluster Sampling\n",
    "\n",
    "As discussed in Module 7.2, we can also use subgraph (cluster) sampling to scale up GNN. Specifically, we will explore the methods proposed in Cluster-GCN ([Chiang et al. (2019)](https://arxiv.org/abs/1905.07953)), where we break our graph into smaller subgraphs to avoid the computational cost of training on the entire graph at once.\n",
    "\n",
    "In this final section, we will implement a vanilla Cluster-GCN and experiment with 3 different community partition algorithms.\n",
    "\n",
    "**NOTE:** the code in this section requires that you have run the `Setup`, `GNN Model` and `Training and Testing` cells of section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BXjP79gUYir"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UGQ_VKp8UOEm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import community.community_louvain as community_louvain\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.graph import Graph\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:   \n",
    "  pyg_dataset = Planetoid('./tmp', \"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "bzMatyCSUaB6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'dropout': 0.5,\n",
    "    'num_layers': 2,\n",
    "    'hidden_size': 64,\n",
    "    'lr': 0.005,\n",
    "    'epochs': 150,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekV-sokSUeLc"
   },
   "source": [
    "## Partitioning the Graph into Clusters\n",
    "\n",
    "We will experiment with three community detection / partition algorithms to partition our graph into different clusters:\n",
    "* [Kernighan–Lin algorithm (bisection)](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.kernighan_lin.kernighan_lin_bisection.html)\n",
    "* [Clauset-Newman-Moore greedy modularity maximization](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.modularity_max.greedy_modularity_communities.html#networkx.algorithms.community.modularity_max.greedy_modularity_communities)\n",
    "* [Louvain algorithm](https://python-louvain.readthedocs.io/en/latest/api.html)\n",
    "\n",
    "\n",
    "As a preprocessing step, we partition our graph into a list of seperate subgraphs using one of the three communitiy detection algorithms above. Then during training we iteratively train our vanilla Cluster-GNN model on a randomly selected subgraph, rather than on over the entire graph at once. To make training more stable, we discard any communities that have less than 10 nodes.\n",
    "\n",
    "Let's begin by defining the three partition algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "N8XeT005UcKh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def partition(G, method=\"louvain\"):\n",
    "    # TODO: Implement a function that takes a Networkx graph G and\n",
    "    # partitions the graph into communities using the specified graph\n",
    "    # partition algorithm.\n",
    "    # \n",
    "    # Return: A list of sets of nodes, one for each community!\n",
    "\n",
    "    communities = None\n",
    "\n",
    "    if method == \"louvain\":\n",
    "        ############# Your code here #############\n",
    "        ## (~9 line of code)\n",
    "        ## Note:\n",
    "        ## 1. Find a community mapping corresponding to the partition of the \n",
    "        ##    graph nodes which maximizes the modularity for the Louvain algorithm. \n",
    "        ##    Set your resolution to 10.\n",
    "        ## 2. Create a mapping of communities to a set of member nodes. \n",
    "        ## 3. Extract the node sets from each community and return \n",
    "        ##    as a list of sets. \n",
    "        ##    Hint: Perhaps a dictionary structure can assist.\n",
    "        ## 4. SET random_state = 8\n",
    "        community_mapping = community_louvain.best_partition(G)\n",
    "        communities = {}\n",
    "        for node in community_mapping:\n",
    "            comm = community_mapping[node]\n",
    "            if comm in communities:\n",
    "                communities[comm].add(node)\n",
    "            else:\n",
    "                communities[comm] = set([node])\n",
    "        communities = communities.values()\n",
    "        ##########################################\n",
    "    elif method == \"bisection\":\n",
    "        ############# Your code here #############\n",
    "        ## (~1 line of code)\n",
    "        ## Note:\n",
    "        ## 1. The Kernigan-Lin algorithm ensures that nodes are partitioned into two \n",
    "        ##    primary communities.  \n",
    "        ## 2. Ensure that the resultant data structure is consistent with expected\n",
    "        ##    output.\n",
    "        ## 3. SET seed = 8\n",
    "        \n",
    "        communities = nx.algorithms.community.kernighan_lin_bisection(G)\n",
    "        ##########################################\n",
    "    elif method == \"greedy\":\n",
    "        ############# Your code here #############\n",
    "        ## (~1 line of code)\n",
    "        ## Note:\n",
    "        ## 1. Clauset-Newman-Moore greedy modularity maximization joins pair \n",
    "        ##    of communities nodes that most increases modularity until no such \n",
    "        ##    pair exists.\n",
    "        communities = nx.algorithms.community.greedy_modularity_communities(G)\n",
    "        pass\n",
    "        ##########################################\n",
    "\n",
    "    return communities \n",
    "\n",
    "\n",
    "def preprocess(G, node_label_index, method=\"louvain\"):\n",
    "    graphs = []\n",
    "    labeled_nodes = set(node_label_index.tolist())\n",
    "\n",
    "    communities = partition(G, method)\n",
    "\n",
    "    for community in communities:\n",
    "        nodes = set(community)\n",
    "        subgraph = G.subgraph(nodes)\n",
    "        # Make sure each subgraph has more than 10 nodes\n",
    "        if subgraph.number_of_nodes() > 10:\n",
    "            node_mapping = {node : i for i, node in enumerate(subgraph.nodes())}\n",
    "            subgraph = nx.relabel_nodes(subgraph, node_mapping)\n",
    "            # Get the id of the training set labeled node in the new graph\n",
    "            train_label_index = []\n",
    "            for node in labeled_nodes:\n",
    "                if node in node_mapping:\n",
    "                    # Append relabeled labeled node index\n",
    "                    train_label_index.append(node_mapping[node])\n",
    "\n",
    "            # Make sure the subgraph contains at least one training set labeled node\n",
    "            if len(train_label_index) > 0:\n",
    "                dg = Graph(subgraph)\n",
    "                # Update node_label_index\n",
    "                dg.node_label_index = torch.tensor(train_label_index, dtype=torch.long)\n",
    "                graphs.append(dg)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKrUdkhC1-A3"
   },
   "source": [
    "## Experimenting with different graph partition algorithms\n",
    "\n",
    "We will now experiment with the three graph partition algorithms, using the resulting graph clusters to train our vanilla Cluster-GNN. We will first observe how each parition algorithm partitions the original graph. Then we will compare the perfomance of our vanilla Cluster-GNN trained using the different graph clustering techniques. Lastly, we will compare against training a vanilla GCN over the entire graph (refered to as Full-Batch training).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CYEamCAU-TJ"
   },
   "source": [
    "## **Question 2.1a:** How does the Louvain algorithm partition our graph? (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-TrC6ybWU7eO",
    "outputId": "27c74405-00b5-4fc5-d70e-a31aaf122985",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index fields: train_mask ignored.\n",
      "Index fields: test_mask ignored.\n",
      "Index fields: val_mask ignored.\n",
      "\n",
      "Partitioning the graph in to 24 communities\n",
      "Each community has 99 nodes in average\n",
      "Each community has 177 edges in average\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "  graphs = preprocess(graph_train.G, graph_train.node_label_index, method=\"louvain\")\n",
    "  print()\n",
    "  print(\"Partitioning the graph in to {} communities\".format(len(graphs)))\n",
    "  avg_num_nodes = 0\n",
    "  avg_num_edges = 0\n",
    "  for graph in graphs:\n",
    "      avg_num_nodes += graph.num_nodes\n",
    "      avg_num_edges += graph.num_edges\n",
    "  avg_num_nodes = int(avg_num_nodes / len(graphs))\n",
    "  avg_num_edges = int(avg_num_edges / len(graphs))\n",
    "  print(\"Each community has {} nodes in average\".format(avg_num_nodes))\n",
    "  print(\"Each community has {} edges in average\".format(avg_num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O03uXIuGVIgJ"
   },
   "source": [
    "## **Question 2.1b:** Using Louvain clustering, what is the maximum test accuracy obtained by your vanilla Cluster-GCN? (6 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSbGf5ADVFQq",
    "outputId": "aa83b270-1976-48af-b883-3fb412f63f8f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 1.9580, Train: 13.57%, Valid: 20.20% Test: 20.80%\n",
      "Epoch: 02, Loss: 2.1239, Train: 20.00%, Valid: 20.40% Test: 19.40%\n",
      "Epoch: 03, Loss: 2.6115, Train: 18.57%, Valid: 17.40% Test: 17.70%\n",
      "Epoch: 04, Loss: 0.2079, Train: 19.29%, Valid: 16.80% Test: 18.30%\n",
      "Epoch: 05, Loss: 1.7966, Train: 20.71%, Valid: 16.20% Test: 16.70%\n",
      "Epoch: 06, Loss: 2.5783, Train: 20.71%, Valid: 17.80% Test: 16.90%\n",
      "Epoch: 07, Loss: 2.6296, Train: 23.57%, Valid: 17.00% Test: 13.70%\n",
      "Epoch: 08, Loss: 2.6578, Train: 21.43%, Valid: 15.20% Test: 12.70%\n",
      "Epoch: 09, Loss: 1.8858, Train: 28.57%, Valid: 13.60% Test: 12.10%\n",
      "Epoch: 10, Loss: 2.2047, Train: 30.71%, Valid: 13.60% Test: 13.10%\n",
      "Epoch: 11, Loss: 2.5752, Train: 35.71%, Valid: 13.80% Test: 13.80%\n",
      "Epoch: 12, Loss: 1.9116, Train: 37.86%, Valid: 14.40% Test: 15.40%\n",
      "Epoch: 13, Loss: 1.6017, Train: 41.43%, Valid: 17.40% Test: 18.70%\n",
      "Epoch: 14, Loss: 2.0866, Train: 38.57%, Valid: 18.40% Test: 21.00%\n",
      "Epoch: 15, Loss: 0.4416, Train: 39.29%, Valid: 18.20% Test: 21.40%\n",
      "Epoch: 16, Loss: 1.3354, Train: 42.14%, Valid: 19.80% Test: 22.00%\n",
      "Epoch: 17, Loss: 0.4394, Train: 45.71%, Valid: 20.20% Test: 21.90%\n",
      "Epoch: 18, Loss: 0.9084, Train: 45.71%, Valid: 21.40% Test: 22.20%\n",
      "Epoch: 19, Loss: 1.3943, Train: 44.29%, Valid: 23.00% Test: 23.10%\n",
      "Epoch: 20, Loss: 1.9906, Train: 45.00%, Valid: 24.00% Test: 23.60%\n",
      "Epoch: 21, Loss: 2.1618, Train: 45.00%, Valid: 26.00% Test: 24.90%\n",
      "Epoch: 22, Loss: 1.0975, Train: 48.57%, Valid: 26.80% Test: 25.60%\n",
      "Epoch: 23, Loss: 0.6575, Train: 51.43%, Valid: 27.00% Test: 27.10%\n",
      "Epoch: 24, Loss: 3.0473, Train: 55.00%, Valid: 26.80% Test: 28.30%\n",
      "Epoch: 25, Loss: 2.4537, Train: 55.71%, Valid: 26.20% Test: 28.30%\n",
      "Epoch: 26, Loss: 2.5985, Train: 59.29%, Valid: 28.60% Test: 27.60%\n",
      "Epoch: 27, Loss: 3.1055, Train: 64.29%, Valid: 27.80% Test: 27.30%\n",
      "Epoch: 28, Loss: 0.3790, Train: 65.71%, Valid: 24.40% Test: 25.70%\n",
      "Epoch: 29, Loss: 2.4654, Train: 68.57%, Valid: 23.40% Test: 23.40%\n",
      "Epoch: 30, Loss: 2.0133, Train: 70.00%, Valid: 21.80% Test: 22.80%\n",
      "Epoch: 31, Loss: 0.8152, Train: 72.86%, Valid: 21.40% Test: 22.50%\n",
      "Epoch: 32, Loss: 0.4503, Train: 71.43%, Valid: 19.80% Test: 20.60%\n",
      "Epoch: 33, Loss: 0.8854, Train: 71.43%, Valid: 19.60% Test: 19.70%\n",
      "Epoch: 34, Loss: 0.6298, Train: 70.71%, Valid: 18.40% Test: 17.60%\n",
      "Epoch: 35, Loss: 2.0633, Train: 70.71%, Valid: 18.40% Test: 18.20%\n",
      "Epoch: 36, Loss: 1.3251, Train: 71.43%, Valid: 17.60% Test: 18.40%\n",
      "Epoch: 37, Loss: 1.2198, Train: 70.71%, Valid: 17.20% Test: 19.30%\n",
      "Epoch: 38, Loss: 0.2503, Train: 72.14%, Valid: 16.60% Test: 20.40%\n",
      "Epoch: 39, Loss: 0.6875, Train: 73.57%, Valid: 16.80% Test: 21.40%\n",
      "Epoch: 40, Loss: 0.6474, Train: 72.14%, Valid: 18.20% Test: 21.60%\n",
      "Epoch: 41, Loss: 2.4912, Train: 71.43%, Valid: 19.60% Test: 23.30%\n",
      "Epoch: 42, Loss: 1.2300, Train: 73.57%, Valid: 21.40% Test: 24.70%\n",
      "Epoch: 43, Loss: 2.0763, Train: 73.57%, Valid: 22.40% Test: 25.70%\n",
      "Epoch: 44, Loss: 0.5313, Train: 73.57%, Valid: 22.60% Test: 25.60%\n",
      "Epoch: 45, Loss: 0.7878, Train: 75.00%, Valid: 21.60% Test: 25.20%\n",
      "Epoch: 46, Loss: 1.1670, Train: 76.43%, Valid: 22.00% Test: 24.90%\n",
      "Epoch: 47, Loss: 0.3027, Train: 77.86%, Valid: 21.80% Test: 24.40%\n",
      "Epoch: 48, Loss: 0.4153, Train: 76.43%, Valid: 22.60% Test: 24.80%\n",
      "Epoch: 49, Loss: 0.5295, Train: 73.57%, Valid: 23.00% Test: 24.80%\n",
      "Epoch: 50, Loss: 0.6653, Train: 72.86%, Valid: 23.80% Test: 23.90%\n",
      "Epoch: 51, Loss: 0.0805, Train: 72.86%, Valid: 23.60% Test: 23.00%\n",
      "Epoch: 52, Loss: 0.5850, Train: 72.86%, Valid: 23.80% Test: 22.70%\n",
      "Epoch: 53, Loss: 2.8795, Train: 72.86%, Valid: 22.00% Test: 22.20%\n",
      "Epoch: 54, Loss: 2.9168, Train: 72.86%, Valid: 21.60% Test: 22.20%\n",
      "Epoch: 55, Loss: 0.0049, Train: 74.29%, Valid: 23.00% Test: 22.20%\n",
      "Epoch: 56, Loss: 0.2334, Train: 77.86%, Valid: 22.00% Test: 22.10%\n",
      "Epoch: 57, Loss: 0.0513, Train: 78.57%, Valid: 22.20% Test: 22.40%\n",
      "Epoch: 58, Loss: 0.0011, Train: 79.29%, Valid: 22.20% Test: 22.80%\n",
      "Epoch: 59, Loss: 0.0001, Train: 78.57%, Valid: 22.00% Test: 22.40%\n",
      "Epoch: 60, Loss: 0.7658, Train: 82.86%, Valid: 21.80% Test: 23.10%\n",
      "Epoch: 61, Loss: 0.1680, Train: 85.71%, Valid: 21.20% Test: 22.80%\n",
      "Epoch: 62, Loss: 0.5268, Train: 89.29%, Valid: 20.80% Test: 23.40%\n",
      "Epoch: 63, Loss: 0.0236, Train: 88.57%, Valid: 20.00% Test: 23.70%\n",
      "Epoch: 64, Loss: 0.4427, Train: 90.00%, Valid: 19.80% Test: 23.90%\n",
      "Epoch: 65, Loss: 0.4740, Train: 90.00%, Valid: 20.00% Test: 24.00%\n",
      "Epoch: 66, Loss: 0.6639, Train: 90.00%, Valid: 21.00% Test: 24.30%\n",
      "Epoch: 67, Loss: 0.0332, Train: 90.00%, Valid: 22.00% Test: 23.60%\n",
      "Epoch: 68, Loss: 0.0981, Train: 88.57%, Valid: 22.60% Test: 23.70%\n",
      "Epoch: 69, Loss: 0.0929, Train: 88.57%, Valid: 22.40% Test: 23.90%\n",
      "Epoch: 70, Loss: 0.0799, Train: 87.14%, Valid: 22.60% Test: 23.60%\n",
      "Epoch: 71, Loss: 0.0075, Train: 86.43%, Valid: 23.40% Test: 23.30%\n",
      "Epoch: 72, Loss: 0.2537, Train: 88.57%, Valid: 22.80% Test: 23.80%\n",
      "Epoch: 73, Loss: 0.5241, Train: 87.86%, Valid: 23.00% Test: 23.60%\n",
      "Epoch: 74, Loss: 0.0515, Train: 87.14%, Valid: 23.20% Test: 24.10%\n",
      "Epoch: 75, Loss: 0.0228, Train: 87.14%, Valid: 23.00% Test: 23.20%\n",
      "Epoch: 76, Loss: 0.2423, Train: 87.14%, Valid: 22.60% Test: 23.60%\n",
      "Epoch: 77, Loss: 0.2659, Train: 86.43%, Valid: 22.00% Test: 23.60%\n",
      "Epoch: 78, Loss: 0.0671, Train: 85.71%, Valid: 22.40% Test: 23.70%\n",
      "Epoch: 79, Loss: 0.1395, Train: 86.43%, Valid: 22.20% Test: 23.30%\n",
      "Epoch: 80, Loss: 0.7761, Train: 86.43%, Valid: 22.40% Test: 24.50%\n",
      "Epoch: 81, Loss: 0.6136, Train: 87.86%, Valid: 23.20% Test: 25.30%\n",
      "Epoch: 82, Loss: 0.5665, Train: 87.86%, Valid: 23.60% Test: 25.30%\n",
      "Epoch: 83, Loss: 0.0443, Train: 87.86%, Valid: 24.20% Test: 25.60%\n",
      "Epoch: 84, Loss: 0.3296, Train: 87.86%, Valid: 24.40% Test: 25.70%\n",
      "Epoch: 85, Loss: 0.0625, Train: 87.86%, Valid: 24.00% Test: 26.20%\n",
      "Epoch: 86, Loss: 1.3629, Train: 87.86%, Valid: 23.20% Test: 26.60%\n",
      "Epoch: 87, Loss: 0.0139, Train: 89.29%, Valid: 23.40% Test: 26.10%\n",
      "Epoch: 88, Loss: 0.2331, Train: 89.29%, Valid: 24.00% Test: 25.60%\n",
      "Epoch: 89, Loss: 0.0056, Train: 90.00%, Valid: 23.40% Test: 25.50%\n",
      "Epoch: 90, Loss: 0.3920, Train: 90.00%, Valid: 24.60% Test: 26.20%\n",
      "Epoch: 91, Loss: 0.0035, Train: 90.00%, Valid: 24.00% Test: 25.80%\n",
      "Epoch: 92, Loss: 0.0009, Train: 90.00%, Valid: 24.00% Test: 26.00%\n",
      "Epoch: 93, Loss: 0.5957, Train: 90.71%, Valid: 24.00% Test: 25.90%\n",
      "Epoch: 94, Loss: 0.1526, Train: 89.29%, Valid: 23.80% Test: 26.30%\n",
      "Epoch: 95, Loss: 0.0011, Train: 90.71%, Valid: 24.20% Test: 25.50%\n",
      "Epoch: 96, Loss: 0.0057, Train: 90.71%, Valid: 23.60% Test: 25.60%\n",
      "Epoch: 97, Loss: 0.0217, Train: 90.00%, Valid: 23.40% Test: 25.80%\n",
      "Epoch: 98, Loss: 0.0356, Train: 90.00%, Valid: 23.80% Test: 25.30%\n",
      "Epoch: 99, Loss: 0.0006, Train: 90.00%, Valid: 22.80% Test: 25.10%\n",
      "Epoch: 100, Loss: 0.0056, Train: 90.00%, Valid: 22.00% Test: 24.80%\n",
      "Epoch: 101, Loss: 0.2680, Train: 90.00%, Valid: 22.00% Test: 25.20%\n",
      "Epoch: 102, Loss: 0.0007, Train: 89.29%, Valid: 22.80% Test: 25.40%\n",
      "Epoch: 103, Loss: 0.0375, Train: 90.00%, Valid: 22.20% Test: 24.80%\n",
      "Epoch: 104, Loss: 0.0424, Train: 90.00%, Valid: 22.60% Test: 24.30%\n",
      "Epoch: 105, Loss: 0.0344, Train: 90.00%, Valid: 22.20% Test: 24.00%\n",
      "Epoch: 106, Loss: 0.0004, Train: 90.00%, Valid: 21.20% Test: 23.50%\n",
      "Epoch: 107, Loss: 0.0087, Train: 90.00%, Valid: 22.20% Test: 23.90%\n",
      "Epoch: 108, Loss: 0.0111, Train: 90.00%, Valid: 21.80% Test: 23.40%\n",
      "Epoch: 109, Loss: 0.4623, Train: 90.71%, Valid: 21.60% Test: 23.70%\n",
      "Epoch: 110, Loss: 0.1959, Train: 90.71%, Valid: 22.00% Test: 24.00%\n",
      "Epoch: 111, Loss: 0.0153, Train: 90.71%, Valid: 21.80% Test: 24.00%\n",
      "Epoch: 112, Loss: 0.0018, Train: 90.71%, Valid: 22.40% Test: 24.30%\n",
      "Epoch: 113, Loss: 0.2206, Train: 90.71%, Valid: 22.60% Test: 24.40%\n",
      "Epoch: 114, Loss: 0.0002, Train: 90.71%, Valid: 23.00% Test: 24.00%\n",
      "Epoch: 115, Loss: 0.0709, Train: 90.71%, Valid: 23.40% Test: 24.20%\n",
      "Epoch: 116, Loss: 0.0300, Train: 90.71%, Valid: 22.80% Test: 24.20%\n",
      "Epoch: 117, Loss: 0.0122, Train: 90.71%, Valid: 23.60% Test: 24.50%\n",
      "Epoch: 118, Loss: 0.2614, Train: 90.71%, Valid: 24.00% Test: 24.10%\n",
      "Epoch: 119, Loss: 0.0144, Train: 90.71%, Valid: 24.40% Test: 24.60%\n",
      "Epoch: 120, Loss: 0.0102, Train: 90.71%, Valid: 23.40% Test: 24.80%\n",
      "Epoch: 121, Loss: 0.2183, Train: 90.71%, Valid: 23.60% Test: 24.60%\n",
      "Epoch: 122, Loss: 0.0004, Train: 90.71%, Valid: 23.40% Test: 24.60%\n",
      "Epoch: 123, Loss: 0.1833, Train: 90.71%, Valid: 23.60% Test: 24.90%\n",
      "Epoch: 124, Loss: 0.0752, Train: 90.71%, Valid: 23.40% Test: 25.20%\n",
      "Epoch: 125, Loss: 0.0477, Train: 90.71%, Valid: 23.20% Test: 25.30%\n",
      "Epoch: 126, Loss: 0.0002, Train: 90.71%, Valid: 23.60% Test: 25.20%\n",
      "Epoch: 127, Loss: 0.0034, Train: 90.71%, Valid: 24.00% Test: 25.10%\n",
      "Epoch: 128, Loss: 0.0001, Train: 90.71%, Valid: 23.80% Test: 25.10%\n",
      "Epoch: 129, Loss: 0.0181, Train: 91.43%, Valid: 25.00% Test: 25.50%\n",
      "Epoch: 130, Loss: 0.0247, Train: 91.43%, Valid: 25.20% Test: 25.50%\n",
      "Epoch: 131, Loss: 0.0966, Train: 91.43%, Valid: 25.00% Test: 26.00%\n",
      "Epoch: 132, Loss: 0.0199, Train: 91.43%, Valid: 24.40% Test: 25.90%\n",
      "Epoch: 133, Loss: 0.0207, Train: 91.43%, Valid: 24.80% Test: 26.10%\n",
      "Epoch: 134, Loss: 0.0281, Train: 91.43%, Valid: 23.80% Test: 25.80%\n",
      "Epoch: 135, Loss: 0.0192, Train: 91.43%, Valid: 24.40% Test: 25.50%\n",
      "Epoch: 136, Loss: 0.0109, Train: 91.43%, Valid: 24.60% Test: 26.00%\n",
      "Epoch: 137, Loss: 0.0661, Train: 91.43%, Valid: 25.80% Test: 25.90%\n",
      "Epoch: 138, Loss: 0.0126, Train: 90.71%, Valid: 25.80% Test: 26.30%\n",
      "Epoch: 139, Loss: 0.0009, Train: 91.43%, Valid: 26.00% Test: 26.20%\n",
      "Epoch: 140, Loss: 0.0003, Train: 90.71%, Valid: 25.40% Test: 25.60%\n",
      "Epoch: 141, Loss: 0.0014, Train: 91.43%, Valid: 25.00% Test: 25.40%\n",
      "Epoch: 142, Loss: 0.0473, Train: 91.43%, Valid: 25.60% Test: 25.40%\n",
      "Epoch: 143, Loss: 0.0354, Train: 91.43%, Valid: 25.40% Test: 25.30%\n",
      "Epoch: 144, Loss: 0.0126, Train: 91.43%, Valid: 24.20% Test: 25.30%\n",
      "Epoch: 145, Loss: 0.0038, Train: 91.43%, Valid: 25.40% Test: 25.20%\n",
      "Epoch: 146, Loss: 0.0221, Train: 91.43%, Valid: 24.00% Test: 25.70%\n",
      "Epoch: 147, Loss: 0.0884, Train: 91.43%, Valid: 23.40% Test: 25.60%\n",
      "Epoch: 148, Loss: 0.0239, Train: 91.43%, Valid: 23.00% Test: 25.30%\n",
      "Epoch: 149, Loss: 0.1616, Train: 91.43%, Valid: 23.00% Test: 25.20%\n",
      "Epoch: 150, Loss: 0.0013, Train: 91.43%, Valid: 22.40% Test: 25.60%\n",
      "Saving Model Predictions for Model: cluster louvain\n",
      "Best model: Train: 59.29%, Valid: 28.60% Test: 27.60%\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "  \n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "\n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  louvain_best_model, louvain_accs = train(graphs, [graph_train, graph_val, graph_test], args, model, optimizer, mode=\"community\")\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], louvain_best_model, save_model_results=True, batch_type=\"cluster\", title=\"louvain\")\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CvTf0ANVO9U"
   },
   "source": [
    "## **Question 2.2a:** How does the Bisection algorithm partition our graph? (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkV0zlhgVJ7u",
    "outputId": "1e59736a-a9b3-49e3-e2a2-e87592a486d6"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "  graphs = preprocess(graph_train.G, graph_train.node_label_index, method=\"bisection\")\n",
    "  print(\"Partition the graph in to {} communities\".format(len(graphs)))\n",
    "  avg_num_nodes = 0\n",
    "  avg_num_edges = 0\n",
    "  for graph in graphs:\n",
    "      avg_num_nodes += graph.num_nodes\n",
    "      avg_num_edges += graph.num_edges\n",
    "  avg_num_nodes = int(avg_num_nodes / len(graphs))\n",
    "  avg_num_edges = int(avg_num_edges / len(graphs))\n",
    "  print(\"Each community has {} nodes in average\".format(avg_num_nodes))\n",
    "  print(\"Each community has {} edges in average\".format(avg_num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqMCvP8wVVms"
   },
   "source": [
    "## **Question 2.2b:** Using the Bisection algorithm to partition the graph, what is the maximum test accuracy obtained by your vanilla Cluster-GCN? (6 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1wgFg1bVRGY",
    "outputId": "3b136c18-6bfd-4364-e966-f4320b81ed61"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "  \n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "\n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  bisection_best_model, bisection_accs = train(graphs, [graph_train, graph_val, graph_test], args, model, optimizer, mode=\"community\")\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], bisection_best_model, save_model_results=True, batch_type=\"cluster\", title=\"bisection\")\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PROPwoOVcJy"
   },
   "source": [
    "## **Question 2.3a:** How does Greedy preprocessing partition our graph? (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3DVamWqVT92",
    "outputId": "edd56562-0cc1-4815-a1f5-e271ff962358"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "  graphs = preprocess(graph_train.G, graph_train.node_label_index, method=\"greedy\")\n",
    "  print(\"Partition the graph in to {} communities\".format(len(graphs)))\n",
    "  avg_num_nodes = 0\n",
    "  avg_num_edges = 0\n",
    "  for graph in graphs:\n",
    "      avg_num_nodes += graph.num_nodes\n",
    "      avg_num_edges += graph.num_edges\n",
    "  avg_num_nodes = int(avg_num_nodes / len(graphs))\n",
    "  avg_num_edges = int(avg_num_edges / len(graphs))\n",
    "  print(\"Each community has {} nodes in average\".format(avg_num_nodes))\n",
    "  print(\"Each community has {} edges in average\".format(avg_num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93pR_-kxVgma"
   },
   "source": [
    "## **Question 2.3b:** Using Greedy preprocessing to partition the graph, what is the maximum test accuracy obtained by your vanilla Cluster-GCN? (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQgQY-jPVd_U",
    "outputId": "5182d19b-ce30-406c-c7e8-1a55b80c429c"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ: \n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "\n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  greedy_best_model, greedy_accs = train(graphs, [graph_train, graph_val, graph_test], args, model, optimizer, mode=\"community\")\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], greedy_best_model, save_model_results=True, batch_type=\"cluster\", title=\"greedy\")\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5edKKT6Vk1C"
   },
   "source": [
    "## Full-Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5tIXxC8ViFD",
    "outputId": "4dbf88f1-dde8-4033-9240-980d27f3a598"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  \n",
    "  set_seed()\n",
    "\n",
    "  graphs_train, graphs_val, graphs_test = \\\n",
    "      GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
    "\n",
    "  graph_train = graphs_train[0]\n",
    "  graph_val = graphs_val[0]\n",
    "  graph_test = graphs_test[0]\n",
    "\n",
    "  model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
    "\n",
    "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
    "  # try:\n",
    "  #   model = torch_geometric.compile(model)\n",
    "  #   print(f\"GNN Model compiled\")\n",
    "  # except Exception as err:\n",
    "  #   print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  graphs = [graph_train, graph_val, graph_test]\n",
    "  all_best_model, all_accs = train(graphs, graphs, args, model, optimizer, mode=\"all\")\n",
    "  train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], all_best_model)\n",
    "  print('Best model:',\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * val_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RpuETv7Vpx0"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "PMK33kY5VmF5",
    "outputId": "369c25d1-6acc-4b35-9cbe-ae90351bcacf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  louvain_results = np.array(louvain_accs)\n",
    "  bisection_results = np.array(bisection_accs)\n",
    "  greedy_results = np.array(greedy_accs)\n",
    "  all_results = np.array(all_accs)\n",
    "\n",
    "  x = np.arange(1, 151)\n",
    "\n",
    "  plt.figure(figsize=(9, 7))\n",
    "\n",
    "  plt.plot(x, louvain_results[:, 1], label=\"Louvain Validation\")\n",
    "  plt.plot(x, louvain_results[:, 2], label=\"Louvain Test\")\n",
    "  plt.plot(x, bisection_results[:, 1], label=\"Bisection Validation\")\n",
    "  plt.plot(x, bisection_results[:, 2], label=\"Bisection Test\")\n",
    "  plt.plot(x, greedy_results[:, 1], label=\"Greedy Validation\")\n",
    "  plt.plot(x, greedy_results[:, 2], label=\"Greedy Test\")\n",
    "  plt.plot(x, all_results[:, 1], label=\"All Validation\")\n",
    "  plt.plot(x, all_results[:, 2], label=\"All Test\")\n",
    "  plt.title('Model Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfucBiYfVYFF"
   },
   "source": [
    "# Submission\n",
    "\n",
    "You will need to submit three files on Gradescope to complete this notebook. \n",
    "\n",
    "1.   Your completed *XCS224W_Colab5.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. \n",
    "2.  *CORA_Node_batch_(0.7,0.9,1).csv*\n",
    "3.  *CORA_Node_batch_(0.3,0.5,1).csv*\n",
    "4.  *CORA_Node_cluster_louvain.csv*\n",
    "5.  *CORA_Node_cluster_greedy.csv*\n",
    "6.  *CORA_Node_cluster_bisection.csv*\n",
    "\n",
    "Download the csv files by selecting the *Folder* icon on the left panel. \n",
    "\n",
    "To submit your work, zip the files downloaded in steps 1-7 above and submit to gradescope. **NOTE:** DO NOT rename any of the downloaded files. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
